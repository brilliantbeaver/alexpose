**Your role**: you are an expert software architect taking initial Jupyter notebook experiments and create a robust, maintainable, well-designed software components for video gait analyses and classification.

**Your task**:
Based on "explore2.ipynb" notebook, propose how best to design a complete GAVD video gait sequence analysis package by refactoring out how to extract bbox, joints and skeletal information from a set of GAVD gait frames -- and how to organize the classes, methods, and configurations using the toplevel "ambient" package and the "ambient.gavd" subpackage.  Our goal is to enable end-to-end gait analysis for a video sequence of people walking (with camera capturing different angles of the gaits), with the goal to be able to identify and classify any new gait sequence as asociated with different health conditions or abnormalities.

Your overall design must include comprehensive tests (pytests and hypothesis proper-based tests) created in the appropriate folders and modules of the toplevel folder "tests".

You must document your overall design, implementations, tutorials and architecture in the `docs` toplevel folder and subfolders (for specific key features or modules).  System diagrams and workflows should be illutrated using mermaid diagrams.  Your documentations must be detailed, with lots of specific examples.  

Make sure to fully understand the current design of the "ambient" package thoroughly first.

We will need to also create a "frontend" app based on NextJS / Tailwind / Bootstrap to enable simple, modern, and easy-to-understand upload and manipulation of different videos, analyses, notes, classifications, etc.  This frontend app must be created in the toplevel folder "frontend", with comprehensive testing frameworks and tests built in.

We will also need to create comprehensive command line equivalent to allow the user to directly invoke specific video or gait analyses using the terminal.  Document clearly the various options, along with complete inline documentations with "-h" and other optional parameters.

Your design must comply with best OOP software engineering practices with SOLID, DRY, YAGNI, modularity, robustness and extensibility.  All configurations must be refactored systematically with dependency injection and extensibility in mind.  All environmental variables must be accessed via the "python_dotenv" package assuming a local ".env" secrets key-values file.

**Goals**:
This project uses open-source pose estimation frameworks, including Google’s MediaPipe and CMU’s OpenPose, to extract human joint and movement data from video. Movements are visualized with OpenCV and FFmpeg through skeletal overlays, and advanced machine learning—including modern LLM-based classification methods—is applied to analyze motion patterns and assess risk indicators associated with chronic medical conditions.

**References**
- GAVD dataset: https://github.com/Rahmyyy/GAVD
- MediaPipe: https://ai.google.dev/edge/mediapipe/solutions/guide
- MediaPipe Pose Estimation: https://ai.google.dev/edge/mediapipe/solutions/vision/pose_landmarker/python


-----------

Let's call this project "alexpose". 

For Requirement 1: we are using GAVD dataset for training and parameter estimations, but we want to use the "alexpose" system (web and cli) to process any video of gait sequences.  Please update all related acceptance criteria and designs.

For Requirement 2: we want to start with using MediaPipe and OpenPose, but ready for other pose estimation packages such as Ultralytics, AlphaPose, etc. 

For Requirement 4: I also want to identify normal versus abnormal gait patterns, and for the abnormal gaits, identify them with conditions that we are using the GAVD (and possibly other) training datasets with.


-----------

For the Application Layer "FastAPI" server, create a new toplevel folder `server` to host those application components and API endpoints.   For the FastAPI server, ensure to use modularity and extensibility to manage endpoints.  Document your design and usage using tutorial style docs in the toplevel `docs` folder.

The "Configuration Environment" should be configs about each of the various components, APIs, and frontends of `alexpose` and not just for the infrastructure layer.  

For the "classifier", the models could also be those of LLMs and custom models and not necessarily TensorFlow/PyTorch.

For IPoseEstimator, can you make sure to re-read our "explore2.ipynb" to see how best to represent a "frame" -- which may have different dimensions and a single np.ndarray may not be sufficient to represent.  Same caution applies to the design of IVideoProcessor for returning frames.  Please generalize the representation of frames for GAVD and YouTube video gait sequences.

For the MediaPipeEstimator and OpenPoseEstimator, please ensure harmonization of what has already been implemented in the `ambient` package versus what are needed based on your updated design and architecture.

For GaitAnalyzer, please perform deep reserach on the latest "Gait" analyses available from authoritative sources of the web including arxiv and update your overall design.

For persistence, let's persist to the toplevel folder `data` and let's minimize any additional system dependencies by using simple storage mechanisms including files, JSON, pickle, sqlite, etc.

For logging, we strongly prefer using loguru with logs saved to the toplevel folder `logs`.

Think deeply about your overall design and update based on the above suggestions.  Add more specific details to your design with clear examples.

----------

Separately create a pyproject.toml in the server folder that is different than the top level project.toml file for running the command line and for testing. For data persistence, use a top level folder called 'data' and appropriate sub folders with clear and  meaningful names. 

For Task 1.4, if FFmpeg is not available, default to using OpenCV instead.

For Phase 2, we strongly prefer using existing working design and components rather than creating duplicate design / components.

For Video Processing, we must natively support YouTube videos via URLs to youtube.com.  We can use the package "yt-dlp" to download youtube videos for processing and analyses.

In your update to the "ambient" package, make sure to not create duplicate functionalities.  We strongly prefer to extend and update what already exists to maximize backward compatibility.  Proceed carefully & systematically.

For classification, create default classifier based on simple LLM-based prompts and examples using agentic best practices from the latest LLM classification techniques.  Prompts must be refactored out into config files for easy updates and modifications.  The default LLM should be an OpenAI LLM "gpt-5-mini" with env config var "OPENAI_API_KEY" as auth key.

For Phase 5 user interface, let's use latest modern components from "Shadcn" (https://ui.shadcn.com/) with clean and subtle design language including subtle drop shadows, hover effects, liquid glass designs, etc.

For the modern UI, create a modern navigation top nav bar with easy to understand menu items for easy navigation with clear context switching, also include clear tooltips and links to well documented feature descriptions and usage information.

Storage of videos should be in the toplevel "data" folder.  Downloaded youtube videos should be in the "data/youtube" folder -- possibly with meaning subfolder names.

For analysis result display, enable modern visualizations including matplotlib, plotly, Seaborn, Bokeh, etc with interactive components for parameter adjustment during real-time analyses with the users.

For testing in Phase 6, minimize the use of "mocks" and instead deeply create tests to uncover root causes.  Separately decorate tests that are "slow" in pytests for separate "pytest -m slow" testing.

For the deployment section, add the requirment to use "uv" as the default package manager.  Also add a dedicated and detailed section for Heroku deployment with lots of clear and specific command examples, parameter considerations.

The overall design principle for this project should be "loosely coupled but tightly coherent" observing best OOP practices including SOLID, DRY, YAGNI, modularity, robustness, and extensibility for maximum code maintainability.

Lastly, make sure to do a comprehensive end-to-end test for each of your key components before you finish.   Fix all issues uncovered during your testing carefully and systematically.