name: Comprehensive Testing

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test-matrix:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.11", "3.12"]
        test-category: ["fast", "slow", "integration"]
      fail-fast: false
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install uv
      uses: astral-sh/setup-uv@v3
      with:
        version: "latest"
    
    - name: Install dependencies
      run: |
        uv sync --all-extras --dev
    
    - name: Run ${{ matrix.test-category }} tests
      run: |
        if [ "${{ matrix.test-category }}" = "fast" ]; then
          uv run pytest -m "fast" --tb=short --cov=ambient --cov=server --cov-report=xml --cov-report=term-missing -v
        elif [ "${{ matrix.test-category }}" = "slow" ]; then
          uv run pytest -m "slow and not performance" --tb=short --cov=ambient --cov=server --cov-report=xml --cov-report=term-missing -v
        elif [ "${{ matrix.test-category }}" = "integration" ]; then
          uv run pytest -m "integration" --tb=short --cov=ambient --cov=server --cov-report=xml --cov-report=term-missing -v
        fi
    
    - name: Upload coverage to Codecov
      if: matrix.test-category == 'fast' && matrix.python-version == '3.12'
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
    
    - name: Store test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ matrix.python-version }}-${{ matrix.test-category }}
        path: |
          coverage.xml
          htmlcov/
          test-results.xml
        retention-days: 30

  quality-gates:
    runs-on: ubuntu-latest
    needs: test-matrix
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.12
      uses: actions/setup-python@v4
      with:
        python-version: "3.12"
    
    - name: Install uv
      uses: astral-sh/setup-uv@v3
      with:
        version: "latest"
    
    - name: Install dependencies
      run: |
        uv sync --all-extras --dev
    
    - name: Run quality gates
      run: |
        uv run python tests/quality/quality_gates.py --report quality_report.json
    
    - name: Upload quality report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: quality-report
        path: quality_report.json
        retention-days: 30
    
    - name: Comment PR with quality results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          try {
            const report = JSON.parse(fs.readFileSync('quality_report.json', 'utf8'));
            const passed = report.overall_passed ? '✅' : '❌';
            const summary = `${passed} Quality Gates: ${report.gates_passed}/${report.total_gates} passed`;
            
            let comment = `## Quality Gate Results\n\n${summary}\n\n`;
            
            if (!report.overall_passed) {
              comment += '### Failed Gates:\n';
              report.results.forEach(result => {
                if (!result.passed) {
                  comment += `- ❌ **${result.gate_name}**: ${result.message}\n`;
                }
              });
            }
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          } catch (error) {
            console.log('Could not read quality report:', error);
          }

  property-tests:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.12
      uses: actions/setup-python@v4
      with:
        python-version: "3.12"
    
    - name: Install uv
      uses: astral-sh/setup-uv@v3
      with:
        version: "latest"
    
    - name: Install dependencies
      run: |
        uv sync --all-extras --dev
    
    - name: Run property-based tests
      run: |
        uv run pytest -m "property" --hypothesis-profile=ci --tb=short -v
      env:
        HYPOTHESIS_PROFILE: ci
    
    - name: Store property test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: property-test-results
        path: |
          .hypothesis/
        retention-days: 30

  security-scan:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.12
      uses: actions/setup-python@v4
      with:
        python-version: "3.12"
    
    - name: Install uv
      uses: astral-sh/setup-uv@v3
      with:
        version: "latest"
    
    - name: Install dependencies
      run: |
        uv sync --all-extras --dev
    
    - name: Run security scan with bandit
      run: |
        uv add bandit[toml]
        uv run bandit -r ambient/ server/ -f json -o bandit-report.json || true
    
    - name: Run safety check
      run: |
        uv add safety
        uv run safety check --json --output safety-report.json || true
    
    - name: Upload security reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
        retention-days: 30

  test-summary:
    runs-on: ubuntu-latest
    needs: [test-matrix, quality-gates, property-tests, security-scan]
    if: always()
    
    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v4
    
    - name: Generate test summary
      run: |
        echo "# Test Execution Summary" > test_summary.md
        echo "" >> test_summary.md
        echo "## Test Matrix Results" >> test_summary.md
        
        # Check if any test jobs failed
        if [ "${{ needs.test-matrix.result }}" != "success" ]; then
          echo "❌ Test matrix failed" >> test_summary.md
        else
          echo "✅ Test matrix passed" >> test_summary.md
        fi
        
        if [ "${{ needs.quality-gates.result }}" != "success" ]; then
          echo "❌ Quality gates failed" >> test_summary.md
        else
          echo "✅ Quality gates passed" >> test_summary.md
        fi
        
        if [ "${{ needs.property-tests.result }}" != "success" ]; then
          echo "❌ Property tests failed" >> test_summary.md
        else
          echo "✅ Property tests passed" >> test_summary.md
        fi
        
        if [ "${{ needs.security-scan.result }}" != "success" ]; then
          echo "⚠️ Security scan completed with warnings" >> test_summary.md
        else
          echo "✅ Security scan passed" >> test_summary.md
        fi
        
        echo "" >> test_summary.md
        echo "## Artifacts Generated" >> test_summary.md
        echo "- Test results and coverage reports" >> test_summary.md
        echo "- Quality gate analysis" >> test_summary.md
        echo "- Property test execution data" >> test_summary.md
        echo "- Security scan reports" >> test_summary.md
        
        cat test_summary.md
    
    - name: Upload test summary
      uses: actions/upload-artifact@v4
      with:
        name: test-summary
        path: test_summary.md
        retention-days: 30